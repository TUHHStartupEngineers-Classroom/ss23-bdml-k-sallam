{"title":"05 LIME","markdown":{"yaml":{"title":"05 LIME","date":"2023-06-08","output":{"html_document":{"toc":true,"toc_float":true,"df_print":"paged","collapsed":false,"number_sections":true,"toc_depth":3}}},"headingText":"Load model","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n    eval = FALSE,\n    message = FALSE,\n    warning = FALSE\n    )\n```\n\n```{r}\n# LIME FEATURE EXPLANATION ----\n\n# 1. Setup ----\n\n# Load Libraries \n\nlibrary(h2o)\nlibrary(recipes)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(lime)\nlibrary(rsample)\n\nproduct_data <- read_csv(\"./01_ml_fund_source/Business\\ Decisions\\ with\\ Machine\\ Learning/product_backorders.csv\")\nproduct_data2 <- product_data %>% \n  mutate(\n      product_backorder = went_on_backorder %>% str_to_lower() %>% str_detect(\"yes\") %>% as.numeric()\n  ) %>% \n  select(-c(went_on_backorder))\nglimpse(product_data)\n\nsplit_obj<- initial_split(product_data2, prop = 0.75)\ntrain_tbl<- training(split_obj)\ntest_tbl<- testing(split_obj)\n\n\n# ML Preprocessing Recipe \nrecipe_obj <- recipe(product_backorder ~., data = train_tbl) %>% \n    step_zv(all_predictors()) %>% \n    step_dummy(all_nominal(),-all_outcomes()) %>%\n    prep()\n\n\nsplit_obj<- initial_split(product_data2, prop = 0.75)\ntrain_tbl<- training(split_obj)\ntest_tbl<- testing(split_obj)\n\n```\n\n```{r}\n# 2. Models ----\n\nh2o.init()\n\nautoml_leader <- h2o.loadModel(\"StackedEnsemble_AllModels_AutoML_20210603_202714/StackedEnsemble_AllModels_AutoML_20210603_210724\")\nautoml_leader\n```\n\n\n# Plot\n```{r}\n# 3.1 Making Predictions ----\n\npredictions_tbl <- automl_leader %>% \n    h2o.predict(newdata = as.h2o(test_tbl)) %>%\n    as.tibble() %>%\n    bind_cols(\n        test_tbl %>%\n            select(everything())\n    )\n\npredictions_tbl\n```\n\n```{r}\nsummary(train_tbl)\n```\n\nTake the explanation data and use the first case to create a plot similar to the output of plot_features().\n\n## Original plot_features()\n```{r}\n# explanation %>% \n#   as.tibble()\n#   \n# case_1 <- explanation %>%\n#     filter(case == 1)\n# \n# case_1 %>%\n#     plot_features()\n# You will need at least the layers geom_col() and coord_flip().\n\nexplainer <- train_tbl %>%\n    select(-product_backorder) %>%\n    lime(\n        model           = automl_leader,\n        bin_continuous  = TRUE,\n        n_bins          = 4,\n        quantile_bins   = TRUE\n    )\n\nexplainer\n\n\nexplanation <- test_tbl %>%\n    slice(1) %>%\n    select(-product_backorder) %>%\n    lime::explain(\n    \n        # Pass our explainer object\n        explainer = explainer,\n        # Because it is a binary classification model: 1\n        n_labels   = 1,\n        # number of features to be returned\n        n_features = 8,\n        # number of localized linear models\n        n_permutations = 5000,\n        # Let's start with 1\n        kernel_width   = 1\n    )\n\nexplanation\n```\n\n```{r}\n\ng <- plot_features(explanation = explanation, ncol = 1, cases = 1)\ng\n```\n\n\n## Bonus Objectives:\nGet your custom plot_features() function to scale to multiple cases\nUse theme arguments to modify the look of the plot\n\n```{r}\nexplanation_multi <- test_tbl %>%\n    slice(1:20) %>%\n    select(-product_backorder) %>%\n    lime::explain(\n        explainer = explainer,\n        n_labels   = 1,\n        n_features = 8,\n        n_permutations = 5000,\n        kernel_width   = 0.5\n    )\n\nexplanation_multi %>%\n    as.tibble()\n\nplot_explanations(explanation_multi)\n\n```\n\n# Part 2: Recreate plot_explanations():\n\nTake the full explanation data and recreate the second plot.\nYou will need at least the layers geom_tile() and facet_wrap().\n\n## Customized plot_features()\n```{r}\ntheme_lime <- function(...) {\n  theme_minimal() +\n    theme(\n      strip.text = element_text(face = 'bold', size = 9),\n      plot.margin = margin(15, 15, 15, 15),\n      legend.background = element_blank(),\n      legend.key = element_blank(),\n      panel.grid.major.y = element_blank(),\n      panel.grid.minor.y = element_blank(),\n      axis.ticks = element_blank(),\n      legend.position = 'bottom',\n      panel.spacing.y = unit(15, 'pt'),\n      strip.text.x = element_text(margin = margin(t = 2, b = 2), hjust = 0),\n      axis.title.y = element_text(margin = margin(r = 10)),\n      axis.title.x = element_text(margin = margin(t = 10)),\n      panel.background = element_rect(fill   = \"transparent\"),\n      panel.border     = element_rect(color = \"black\", fill = NA, size = 0.5),\n      panel.grid.major = element_line(color = \"grey\", size = 0.333),\n      ...\n    )\n}\n\nplot_explanations_customized <- function(explanation, ...) {\n\n  num_cases <- unique(suppressWarnings(as.numeric(explanation$case)))\n  if (!anyNA(num_cases)) {\n    explanation$case <- factor(explanation$case, levels = as.character(sort(num_cases)))\n  }\n  explanation$feature_desc <- factor(\n    explanation$feature_desc,\n    levels = rev(unique(explanation$feature_desc[order(explanation$feature, explanation$feature_value)]))\n  )\n  \np <- ggplot(explanation, aes_(~case, ~feature_desc),show.legend=TRUE) +\n    geom_tile(aes_(fill = ~feature_weight)) +\n    scale_x_discrete('Case', expand = c(0, 0)) +\n    scale_y_discrete('Feature', expand = c(0, 0)) +\n    scale_fill_gradient2('Feature\\nweight', low = 'firebrick', mid = '#f7f7f7', high = 'steelblue') +\n    theme_lime() +\n    theme(panel.border = element_rect(fill = NA, colour = 'grey60', size = 1),\n          panel.grid = element_blank(),\n          legend.position = 'right',\n          axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))\n  if (is.null(explanation$label)) {\n    p\n  } else {\n    p + facet_wrap(~label, ...)\n  }\n}\n\n```\n\n```{r}\nplot_explanations_customized(explanation = explanation, ncol = 1, cases = 1)\n```\n\n```{r}\nplot_explanations_customized(explanation_multi)\n```"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"paged","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":{"html_document":{"toc":true,"toc_float":true,"df_print":"paged","collapsed":false,"number_sections":true,"toc_depth":3}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":true,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["lightbox"],"highlight-style":"a11y-dark","toc":true,"toc-depth":2,"number-sections":true,"output-file":"05_lime.html"},"language":{"code-summary":"Show the code"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.475","lightbox":"auto","theme":{"dark":"darkly","light":"flatly"},"author":"Joschka Schwarz","knitr":{"opts_chunk":{"comment":"#>","R.options":"dplyr.summarise.inform = FALSE"}},"toc-title":"Contents","number-depth":2,"title":"05 LIME","date":"2023-06-08"},"extensions":{"book":{"multiFile":true}}}}}