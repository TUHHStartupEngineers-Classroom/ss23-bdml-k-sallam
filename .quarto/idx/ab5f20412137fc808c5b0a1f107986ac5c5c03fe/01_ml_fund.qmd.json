{"title":"01 Machine Learning Fundamentals","markdown":{"yaml":{"title":"01 Machine Learning Fundamentals","date":"2023-06-08","output":{"html_document":{"toc":"yes","theme":"flatly","highlight":"tango","code_folding":"hide","df_print":"paged"},"pdf_document":{"toc":"yes"}}},"headingText":"Libraries","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n    eval = FALSE,\n    message = FALSE,\n    warning = FALSE\n    )\n```\n\n\nLoad the following libraries. \n\n\n```{r}\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(broom)\nlibrary(umap)\nlibrary(magrittr) \nlibrary(dplyr)    \nlibrary(ggplot2)\n```\n\n\n# Data\n\nWe will be using stock prices in this analysis. Although some of you know already how to use an API to retrieve stock prices I obtained the stock prices for every stock in the S&P 500 index for you already. The files are saved in the `session_6_data` directory. \n\nWe can read in the stock prices. The data is 1.2M observations. The most important columns for our analysis are:\n\n- `symbol`: The stock ticker symbol that corresponds to a company's stock price\n- `date`: The timestamp relating the symbol to the share price at that point in time\n- `adjusted`: The stock price, adjusted for any splits and dividends (we use this when analyzing stock data over long periods of time) \n\n\n```{r}\n# STOCK PRICES\nsp_500_prices_tbl <- read_rds(\"Data/Data/sp_500_prices_tbl.rds\")\nsp_500_prices_tbl\n```\n\nThe second data frame contains information about the stocks the most important of which are:\n\n- `company`: The company name\n- `sector`: The sector that the company belongs to\n\n```{r}\n# SECTOR INFORMATION\nsp_500_index_tbl <- read_rds(\"raw_data/sp_500_index_tbl.rds\")\nsp_500_index_tbl\n```\n\n\n# Question\n\n<mark>Which stock prices behave similarly?</mark>\n\nAnswering this question helps us __understand which companies are related__, and we can use clustering to help us answer it!\n\nEven if you're not interested in finance, this is still a great analysis because it will tell you which companies are competitors and which are likely in the same space (often called sectors) and can be categorized together. Bottom line - This analysis can help you better understand the dynamics of the market and competition, which is useful for all types of analyses from finance to sales to marketing.  \n\nLet's get started. \n\n## Step 1 - Convert stock prices to a standardized format (daily returns)\n\nWhat you first need to do is get the data in a format that can be converted to a \"user-item\" style matrix. The challenge here is to connect the dots between what we have and what we need to do to format it properly.\n\nWe know that in order to compare the data, it needs to be standardized or normalized. Why? Because we cannot compare values (stock prices) that are of completely different magnitudes. In order to standardize, we will convert from adjusted stock price (dollar value) to daily returns (percent change from previous day). Here is the formula. \n\n$$ \nreturn_{daily} = \\frac{price_{i}-price_{i-1}}{price_{i-1}}\n$$\n\nFirst, what do we have? We have stock prices for every stock in the [SP 500 Index](https://finance.yahoo.com/quote/%5EGSPC?p=%5EGSPC), which is the daily stock prices for over 500 stocks. The data set is over 1.2M observations. \n\n```{r}\nsp_500_prices_tbl %>% glimpse()\n```\n\nYour first task is to convert to a tibble named `sp_500_daily_returns_tbl` by performing the following operations:\n\n- Select the `symbol`, `date` and `adjusted` columns\n- Filter to dates beginning in the year 2018 and beyond. \n- Compute a Lag of 1 day on the adjusted stock price. Be sure to group by symbol first, otherwise we will have lags computed using values from the previous stock in the data frame. \n- Remove a `NA` values from the lagging operation\n- Compute the difference between adjusted and the lag\n- Compute the percentage difference by dividing the difference by that lag. Name this column `pct_return`.\n- Return only the `symbol`, `date`, and `pct_return` columns\n- Save as a variable named `sp_500_daily_returns_tbl`\n\n```{r}\nsp_500_daily_returns_tbl <- select(sp_500_prices_tbl, symbol, date, adjusted)%>%\n  filter(date >= as.Date(\"2018-01-01\"))%>%\n  group_by(symbol)%>%\n  mutate(lag = lag(adjusted))%>%\n  na.exclude()%>%\n  mutate(diff = adjusted - lag)%>%\n  mutate(pct_return = diff / lag)%>%\n  select(symbol, date, pct_return)%>%\n  ungroup()\n\nsp_500_daily_returns_tbl\n\n```\n\n\n## Step 2 - Convert to User-Item Format\n\nThe next step is to convert to a user-item format with the `symbol` in the first column and every other column the value of the _daily returns_ (`pct_return`) for every stock at each `date`.\n\nWe're going to import the correct results first (just in case you were not able to complete the last step).\n\n\n\nNow that we have the daily returns (percentage change from one day to the next), we can convert to a user-item format. The user in this case is the `symbol` (company), and the item in this case is the `pct_return` at each `date`. \n\n- Spread the `date` column to get the values as percentage returns. Make sure to fill an `NA` values with zeros. \n- Save the result as `stock_date_matrix_tbl`\n\n```{r}\n# Convert to User-Item Format\nstock_date_matrix_tbl <- sp_500_daily_returns_tbl%>%\n  spread(date, pct_return, fill = 0)%>%\n  ungroup()\n\nstock_date_matrix_tbl\n# Output: stock_date_matrix_tbl\n```\n\n\n\n## Step 3 - Perform K-Means Clustering\n\nNext, we'll perform __K-Means clustering__. \n\nWe're going to import the correct results first (just in case you were not able to complete the last step).\n```{r}\nstock_date_matrix_tbl <- read_rds(\"raw_data/stock_date_matrix_tbl.rds\")\n```\n\n\n```{r}\nsp_500_daily_returns_tbl <- read_rds(\"Data/Data/sp_500_prices_tbl.rds\")\nsp_500_daily_returns_tbl\n```\n\nBeginning with the `stock_date_matrix_tbl`, perform the following operations:\n\n- Drop the non-numeric column, `symbol`\n- Perform `kmeans()` with `centers = 4` and `nstart = 20`\n- Save the result as `kmeans_obj`\n\n```{r}\n# Create kmeans_obj for 4 centers\nkmeans_obj <- stock_date_matrix_tbl%>%\n  subset(select = -c(symbol))%>%\n  kmeans(centers = 4, nstart = 20)\n\n```\n\nUse `glance()` to get the `tot.withinss`. \n\n```{r}\n# Apply glance() to get the tot.withinss\nbroom::glance(kmeans_obj)\n\n```\n\n## Step 4 - Find the optimal value of K\n\nNow that we are familiar with the process for calculating `kmeans()`, let's use `purrr` to iterate over many values of \"k\" using the `centers` argument. \n\nWe'll use this __custom function__ called `kmeans_mapper()`:\n\n```{r}\nkmeans_mapper <- function(center = 3) {\n    stock_date_matrix_tbl %>%\n        select(-symbol) %>%\n        kmeans(centers = center, nstart = 20)\n}\n```\n\nApply the `kmeans_mapper()` and `glance()` functions iteratively using `purrr`.\n\n- Create a tibble containing column called `centers` that go from 1 to 30\n- Add a column named `k_means` with the `kmeans_mapper()` output. Use `mutate()` to add the column and `map()` to map centers to the `kmeans_mapper()` function.\n- Add a column named `glance` with the `glance()` output. Use `mutate()` and `map()` again to iterate over the column of `k_means`.\n- Save the output as `k_means_mapped_tbl` \n\n\n```{r}\n# Use purrr to map\nkmeans_mapped_tbl <- tibble(centers = 1:30)%>%\n  mutate(k_means = centers %>% map(kmeans_mapper))%>%\n  mutate(glance  = k_means %>% map(glance))\n\n# Output: k_means_mapped_tbl \n```\n\nNext, let's visualize the \"tot.withinss\" from the glance output as a ___Scree Plot___. \n\n- Begin with the `k_means_mapped_tbl`\n- Unnest the `glance` column\n- Plot the `centers` column (x-axis) versus the `tot.withinss` column (y-axis) using `geom_point()` and `geom_line()`\n- Add a title \"Scree Plot\" and feel free to style it with your favorite theme\n\n```{r}\n# Visualize Scree Plot\nkmeans_mapped_tbl %>%\n  unnest(glance)%>%\n  select(centers, tot.withinss)%>%\n  \n  # visualization\n  ggplot(aes(centers, tot.withinss)) +\n  geom_point(color = \"#2DC6D6\", size = 4) +\n  geom_line(color = \"#2DC6D6\", size = 1) +\n    \n  # Add labels (which are repelled a little)\n  ggrepel::geom_label_repel(aes(label = centers), color = \"#2DC6D6\") + \n      \n  # Formatting\n  labs(title = \"Scree Plot\",\n  subtitle = \"\",\n  caption = \"Conclusion: Based on the Scree Plot, we select 3 clusters to segment the company base.\")\n```\n\nWe can see that the Scree Plot becomes linear (constant rate of change) between 5 and 10 centers for K.\n\n\n## Step 5 - Apply UMAP\n\nNext, let's plot the `UMAP` 2D visualization to help us investigate cluster assignments. \n\n\nWe're going to import the correct results first (just in case you were not able to complete the last step).\n```{r}\nk_means_mapped_tbl <- read_rds(\"raw_data/k_means_mapped_tbl.rds\")\n```\n\nFirst, let's apply the `umap()` function to the `stock_date_matrix_tbl`, which contains our user-item matrix in tibble format.\n\n- Start with `stock_date_matrix_tbl`\n- De-select the `symbol` column\n- Use the `umap()` function storing the output as `umap_results`\n```{r}\n# Apply UMAP\n\numap_results <- stock_date_matrix_tbl%>%\n  select(-symbol)%>%\n  umap()\n\n# Store results as: umap_results \n```\n\nNext, we want to combine the `layout` from the `umap_results` with the `symbol` column from the `stock_date_matrix_tbl`.\n\n- Start with `umap_results$layout`\n- Convert from a `matrix` data type to a `tibble` with `as_tibble()`\n- Bind the columns of the umap tibble with the `symbol` column from the `stock_date_matrix_tbl`.\n- Save the results as `umap_results_tbl`.\n\n```{r}\n# Convert umap results to tibble with symbols\numap_results_tbl <- umap_results$layout%>%\n  as_tibble(.name_repair = \"unique\")%>%\n  set_names(c(\"x\", \"y\"))%>%\n    bind_cols(\n        stock_date_matrix_tbl %>% select(symbol)\n    )\n\n# Output: umap_results_tbl\n```\n\nFinally, let's make a quick visualization of the `umap_results_tbl`.\n\n- Pipe the `umap_results_tbl` into `ggplot()` mapping the columns to x-axis and y-axis\n- Add a `geom_point()` geometry with an `alpha = 0.5`\n- Apply `theme_tq()` and add a title \"UMAP Projection\"\n\n```{r}\n# Visualize UMAP results\n\numap_results_tbl %>%\n    ggplot(aes(x, y)) +\n    geom_point(alpha = 0.5) + \n    labs(title = \"UMAP Projection\") +\n    theme_tq()\n```\n\nWe can now see that we have some clusters. However, we still need to combine the K-Means clusters and the UMAP 2D representation. \n\n\n\n## Step 6 - Combine K-Means and UMAP\n\nNext, we combine the K-Means clusters and the UMAP 2D representation\n\nWe're going to import the correct results first (just in case you were not able to complete the last step).\n```{r}\nk_means_mapped_tbl <- read_rds(\"raw_data/k_means_mapped_tbl.rds\")\numap_results_tbl   <- read_rds(\"raw_data/umap_results_tbl.rds\")\n```\n\n\nFirst, pull out the K-Means for 10 Centers. Use this since beyond this value the Scree Plot flattens. \nHave a look at the business case to recall how that works.\n\n```{r}\n# Get the k_means_obj from the 10th center\n\nk_means_obj <- kmeans_mapped_tbl %>%\n    pull(k_means) %>%\n    pluck(3)\n```\n\nNext, we'll combine the clusters from the `k_means_obj` with the `umap_results_tbl`.\n\n- Begin with the `k_means_obj`\n- Augment the `k_means_obj` with the `stock_date_matrix_tbl` to get the clusters added to the end of the tibble\n- Select just the `symbol` and `.cluster` columns\n- Left join the result with the `umap_results_tbl` by the `symbol` column\n- Left join the result with the result of `sp_500_index_tbl %>% select(symbol, company, sector)` by the `symbol` column. \n- Store the output as `umap_kmeans_results_tbl`\n\n\n```{r}\n  # Use your dplyr & broom skills to combine the k_means_obj with the umap_results_tbl\numap_kmeans_clusters_tbl <- k_means_obj %>% \n    augment(stock_date_matrix_tbl) %>%\n    select(symbol, .cluster)\n    \n  umap_kmeans_results_tbl <- umap_results_tbl %>%\n    left_join(umap_kmeans_clusters_tbl, by = \"symbol\")%>%\n    left_join(sp_500_index_tbl %>% select(symbol, company, sector), by = \"symbol\")\n\n umap_kmeans_results_tbl \n```\n\n\nPlot the K-Means and UMAP results.\n\n- Begin with the `umap_kmeans_results_tbl`\n- Use `ggplot()` mapping `V1`, `V2` and `color = .cluster`\n- Add the `geom_point()` geometry with `alpha = 0.5`\n- Apply colors as you desire (e.g. `scale_color_manual(values = palette_light() %>% rep(3))`)\n\n```{r}\n# Visualize the combined K-Means and UMAP results\numap_kmeans_results_tbl %>%\n    ggplot(aes(V1, V2, color = .cluster)) +\n    geom_point(alpha = 0.5)\numap_kmeans_results_tbl\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":{"html_document":{"toc":"yes","theme":"flatly","highlight":"tango","code_folding":"hide","df_print":"paged"},"pdf_document":{"toc":"yes"}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["lightbox"],"highlight-style":"a11y-dark","output-file":"01_ml_fund.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.475","lightbox":"auto","theme":{"dark":"darkly","light":"flatly"},"title":"01 Machine Learning Fundamentals","date":"2023-06-08"},"extensions":{"book":{"multiFile":true}}}}}